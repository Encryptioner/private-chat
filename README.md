# Private AI Chat Assistant: Pure Browser, Zero Backend

## Download and run local LLMs within your browser.

https://github.com/user-attachments/assets/ebeb24ae-cd52-4c43-96d6-c535f2e51f8f

Live site: https://private-ai-chat-assistant.vercel.app/

## Running locally

1. Install dependencies
```
npm install
```

2. Start web app
```
npm run dev
```

3. Navigate to http://localhost:5173/ 

## Credits
- [Wllama](https://github.com/ngxson/wllama)
- SmolLm - [HuggingFace](https://huggingface.co/HuggingFaceTB)
- Llama 3.2 - [Meta](https://www.llama.com/)

